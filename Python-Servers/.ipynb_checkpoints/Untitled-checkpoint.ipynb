{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e76502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections.abc import Mapping\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download the pre-trained Word2Vec model\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17eec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5c30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    text = ' '.join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac7d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8483899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vector(text):\n",
    "    word_embeddings = []\n",
    "    for word in text.split():\n",
    "        try:\n",
    "            embedding = w2v_model[word]\n",
    "            word_embeddings.append(embedding)\n",
    "        except KeyError:\n",
    "            # If the word is not found in the vocabulary, skip it\n",
    "            pass\n",
    "    \n",
    "    if len(word_embeddings) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Calculate the average of word embeddings\n",
    "    text_vector = np.mean(word_embeddings, axis=0)\n",
    "    return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_between_texts(text1, text2, limm=True):\n",
    "    # Preprocess the texts\n",
    "    if limm == True:\n",
    "        preprocessed_text1 = apply_lemmatization(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_lemmatization(preprocess_text(text2))\n",
    "    else:\n",
    "        preprocessed_text1 = apply_stemming(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_stemming(preprocess_text(text2))\n",
    "    \n",
    "    # Get text vectors\n",
    "    vector1 = get_text_vector(preprocessed_text1)\n",
    "    vector2 = get_text_vector(preprocessed_text2)\n",
    "    \n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c12c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Text 1 and Text 2 with lemmatization: 0.49738303\n",
      "Cosine Similarity between Text 1 and Text 2 with stemming: 0.46470538\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Tokenization is an important step in natural language processing.\"\n",
    "text2 = \"Sentence tokenization is a technique used to split text into sentences.\"\n",
    "\n",
    "# Calculate cosine similarity between texts\n",
    "similarity = cosine_similarity_between_texts(text1, text2)\n",
    "\n",
    "print(\"Cosine Similarity between Text 1 and Text 2 with lemmatization:\", similarity)\n",
    "similarity = cosine_similarity_between_texts(text1, text2, False)\n",
    "print(\"Cosine Similarity between Text 1 and Text 2 with stemming:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703b4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "db = mysql.connector.connect(user='root', password='Jana2003?',\n",
    "                              host='127.0.0.1', database='grad',\n",
    "                              auth_plugin='mysql_native_password')\n",
    "cursor = db.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_users_note_except_user_and_followed(username_to_exclude):\n",
    "    # Fetch the list of users that the specified user follows\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT following_id\n",
    "        FROM followers\n",
    "        WHERE follower_id = '{username_to_exclude}'\n",
    "    \"\"\")\n",
    "    followed_users = cursor.fetchall()\n",
    "    \n",
    "    # Extract the list of followed user IDs\n",
    "    followed_user_ids = [user[0] for user in followed_users]\n",
    "    \n",
    "    # Convert the list to a string format suitable for SQL IN clause\n",
    "    followed_user_ids_str = \"', '\".join(followed_user_ids)\n",
    "    \n",
    "    # Include the specified user in the exclusion list\n",
    "    followed_user_ids_str = f\"'{username_to_exclude}', '{followed_user_ids_str}'\"\n",
    "    \n",
    "    # Fetch notes excluding those from the specified user and followed users\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM note\n",
    "        WHERE user_id NOT IN ({followed_user_ids_str})\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    notes = cursor.fetchall()\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2a7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa\n",
      "a\n",
      "aaaaa\n",
      "saraa\n",
      "b\n",
      "sara\n",
      "saraa\n",
      "saraa\n",
      "aaa\n",
      "aaa\n",
      "a\n",
      "a\n",
      "aa\n",
      "aa\n",
      "a\n",
      "jana\n",
      "aa\n",
      "aa\n",
      "jana\n",
      "sara\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "all_users_post_except_specific_user = get_all_users_note_except_user_and_followed(\"rama\")\n",
    "for post in all_users_post_except_specific_user:\n",
    "    print(post[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63d1965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_user_posts(username):\n",
    "    cursor.execute(f\"SELECT text FROM note WHERE user_id = '{username}'\")\n",
    "    posts = cursor.fetchall()\n",
    "    # Convert each tuple to a string\n",
    "    posts_as_strings = [post[0] for post in posts]\n",
    "    return posts_as_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb1b8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_user_posts_using_cosine(user_name, number_of_posts):\n",
    "    user_posts = get_all_user_posts(user_name)\n",
    "\n",
    "    # Get all other users' posts\n",
    "    other_users_posts = get_all_users_note_except_user_and_followed(user_name)\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Initialize a set to store the IDs of processed posts\n",
    "    processed_post_ids = set()\n",
    "\n",
    "    # Loop through each other user's post\n",
    "    for post in other_users_posts:\n",
    "        # Calculate cosine similarity between each user post and the current post\n",
    "        for user_post in user_posts:\n",
    "            similarity = cosine_similarity_between_texts(user_post, post[3])\n",
    "            if similarity and post[0] not in processed_post_ids:  # Check if similarity is not None and post not processed\n",
    "                recommendations.append({\n",
    "                    'id': post[0],              # Get the post ID from the tuple\n",
    "                    'creation_time': post[1],   # Get the creation time from the tuple\n",
    "                    'user_id': post[2],         # Get the user ID from the tuple\n",
    "                    'text': post[3],            # Get the post text from the tuple\n",
    "                    'url': post[4],             # Get the URL from the tuple\n",
    "                    'comment': post[5],         # Get the comment from the tuple\n",
    "                    'similarity': similarity    # Include the calculated similarity\n",
    "                })\n",
    "                # Add the post ID to the set of processed post IDs\n",
    "                processed_post_ids.add(post[0])\n",
    "\n",
    "    # Sort recommendations by similarity (highest first)\n",
    "    recommendations.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Return only the requested number of recommendations\n",
    "    return recommendations[:number_of_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "762dc04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 10,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 22, 79000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Providing timely and constructive feedback is essential for student growth and improvement.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.63822603},\n",
       " {'id': 9,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 20, 91000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Engaging students through interactive activities helps enhance understanding and retention.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.6114806},\n",
       " {'id': 14,\n",
       "  'creation_time': datetime.datetime(2024, 4, 30, 23, 42, 17, 463000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Tailoring instruction to meet diverse student needs ensures that all learners can succeed.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Your%20Own',\n",
       "  'comment': 'bbbb',\n",
       "  'similarity': 0.59020835},\n",
       " {'id': 15,\n",
       "  'creation_time': datetime.datetime(2024, 5, 1, 18, 27, 2, 325000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Using technology in the classroom can enhance learning experiences and access to information.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Google%20Chrome',\n",
       "  'comment': 'bhbhbh',\n",
       "  'similarity': 0.56750226},\n",
       " {'id': 27,\n",
       "  'creation_time': datetime.datetime(2024, 5, 26, 9, 37, 24, 205000),\n",
       "  'user_id': 'sara',\n",
       "  'text': 'Understanding algorithms is crucial for problem-solving and optimizing code performance.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension#:~:text=Extension',\n",
       "  'comment': 'save plzzzz',\n",
       "  'similarity': 0.45019576}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_user_posts_using_cosine(\"aa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ec151e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def euclidean_similarity_between_texts(text1, text2, limm=True):\n",
    "    # Preprocess the texts\n",
    "    if limm == True:\n",
    "        preprocessed_text1 = apply_lemmatization(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_lemmatization(preprocess_text(text2))\n",
    "    else:\n",
    "        preprocessed_text1 = apply_stemming(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_stemming(preprocess_text(text2))\n",
    "    \n",
    "    # Get text vectors\n",
    "    vector1 = get_text_vector(preprocessed_text1)\n",
    "    vector2 = get_text_vector(preprocessed_text2)\n",
    "    \n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate Euclidean distance\n",
    "    distance = euclidean_distances([vector1], [vector2])[0][0]\n",
    "    \n",
    "    # Convert distance to similarity\n",
    "    similarity = 1 / (1 + distance)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "48de089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_user_posts_using_euclidean_distances(user_name, number_of_posts):\n",
    "    \n",
    "    user_posts = get_all_user_posts(user_name)\n",
    "\n",
    "    # Get all other users' posts\n",
    "    other_users_posts = get_all_users_note_except_user_and_followed(user_name)\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Initialize a set to store the IDs of processed posts\n",
    "    processed_post_ids = set()\n",
    "\n",
    "    # Loop through each other user's post\n",
    "    for post in other_users_posts:\n",
    "        # Calculate cosine similarity between each user post and the current post\n",
    "        for user_post in user_posts:\n",
    "            similarity = euclidean_similarity_between_texts(user_post, post[3])\n",
    "            if similarity and post[0] not in processed_post_ids:  # Check if similarity is not None and post not processed\n",
    "                recommendations.append({\n",
    "                    'id': post[0],              # Get the post ID from the tuple\n",
    "                    'creation_time': post[1],   # Get the creation time from the tuple\n",
    "                    'user_id': post[2],         # Get the user ID from the tuple\n",
    "                    'text': post[3],            # Get the post text from the tuple\n",
    "                    'url': post[4],             # Get the URL from the tuple\n",
    "                    'comment': post[5],         # Get the comment from the tuple\n",
    "                    'similarity': similarity    # Include the calculated similarity\n",
    "                })\n",
    "                # Add the post ID to the set of processed post IDs\n",
    "                processed_post_ids.add(post[0])\n",
    "\n",
    "    # Sort recommendations by similarity (highest first)\n",
    "    recommendations.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Return only the requested number of recommendations\n",
    "    return recommendations[:number_of_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0a50e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 9,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 20, 91000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Engaging students through interactive activities helps enhance understanding and retention.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.4728127036489725},\n",
       " {'id': 10,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 22, 79000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Providing timely and constructive feedback is essential for student growth and improvement.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.47229727934145316},\n",
       " {'id': 14,\n",
       "  'creation_time': datetime.datetime(2024, 4, 30, 23, 42, 17, 463000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Tailoring instruction to meet diverse student needs ensures that all learners can succeed.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Your%20Own',\n",
       "  'comment': 'bbbb',\n",
       "  'similarity': 0.46432169471112933},\n",
       " {'id': 15,\n",
       "  'creation_time': datetime.datetime(2024, 5, 1, 18, 27, 2, 325000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Using technology in the classroom can enhance learning experiences and access to information.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Google%20Chrome',\n",
       "  'comment': 'bhbhbh',\n",
       "  'similarity': 0.4528749672501949},\n",
       " {'id': 27,\n",
       "  'creation_time': datetime.datetime(2024, 5, 26, 9, 37, 24, 205000),\n",
       "  'user_id': 'sara',\n",
       "  'text': 'Understanding algorithms is crucial for problem-solving and optimizing code performance.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension#:~:text=Extension',\n",
       "  'comment': 'save plzzzz',\n",
       "  'similarity': 0.4265332665478514}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_user_posts_using_euclidean_distances(\"aa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "892401cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_similarity_between_texts(text1, text2, limm=True):\n",
    "    # Preprocess the texts\n",
    "    if limm == True:\n",
    "        preprocessed_text1 = apply_lemmatization(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_lemmatization(preprocess_text(text2))\n",
    "    else:\n",
    "        preprocessed_text1 = apply_stemming(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_stemming(preprocess_text(text2))\n",
    "    \n",
    "    # Get text vectors\n",
    "    vector1 = get_text_vector(preprocessed_text1)\n",
    "    vector2 = get_text_vector(preprocessed_text2)\n",
    "    \n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    \n",
    "    # Normalize vectors\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc146366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_user_posts_using_dot_product(user_name, number_of_posts):\n",
    "    \n",
    "    user_posts = get_all_user_posts(user_name)\n",
    "\n",
    "    # Get all other users' posts\n",
    "    other_users_posts = get_all_users_note_except_user_and_followed(user_name)\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Initialize a set to store the IDs of processed posts\n",
    "    processed_post_ids = set()\n",
    "\n",
    "    # Loop through each other user's post\n",
    "    for post in other_users_posts:\n",
    "        # Calculate cosine similarity between each user post and the current post\n",
    "        for user_post in user_posts:\n",
    "            similarity = dot_product_similarity_between_texts(user_post, post[3])\n",
    "            if similarity and post[0] not in processed_post_ids:  # Check if similarity is not None and post not processed\n",
    "                recommendations.append({\n",
    "                    'id': post[0],              # Get the post ID from the tuple\n",
    "                    'creation_time': post[1],   # Get the creation time from the tuple\n",
    "                    'user_id': post[2],         # Get the user ID from the tuple\n",
    "                    'text': post[3],            # Get the post text from the tuple\n",
    "                    'url': post[4],             # Get the URL from the tuple\n",
    "                    'comment': post[5],         # Get the comment from the tuple\n",
    "                    'similarity': similarity    # Include the calculated similarity\n",
    "                })\n",
    "                # Add the post ID to the set of processed post IDs\n",
    "                processed_post_ids.add(post[0])\n",
    "\n",
    "    # Sort recommendations by similarity (highest first)\n",
    "    recommendations.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Return only the requested number of recommendations\n",
    "    return recommendations[:number_of_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b76e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 10,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 22, 79000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Providing timely and constructive feedback is essential for student growth and improvement.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.638226},\n",
       " {'id': 9,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 20, 91000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Engaging students through interactive activities helps enhance understanding and retention.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.61148053},\n",
       " {'id': 14,\n",
       "  'creation_time': datetime.datetime(2024, 4, 30, 23, 42, 17, 463000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Tailoring instruction to meet diverse student needs ensures that all learners can succeed.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Your%20Own',\n",
       "  'comment': 'bbbb',\n",
       "  'similarity': 0.59020835},\n",
       " {'id': 15,\n",
       "  'creation_time': datetime.datetime(2024, 5, 1, 18, 27, 2, 325000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Using technology in the classroom can enhance learning experiences and access to information.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Google%20Chrome',\n",
       "  'comment': 'bhbhbh',\n",
       "  'similarity': 0.5675022},\n",
       " {'id': 27,\n",
       "  'creation_time': datetime.datetime(2024, 5, 26, 9, 37, 24, 205000),\n",
       "  'user_id': 'sara',\n",
       "  'text': 'Understanding algorithms is crucial for problem-solving and optimizing code performance.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension#:~:text=Extension',\n",
       "  'comment': 'save plzzzz',\n",
       "  'similarity': 0.4501958}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_user_posts_using_dot_product(\"aa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d82a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('street performer', 0.6253), ('melody glow', 0.5632), ('mesmerizing melody', 0.5517), ('solitary street', 0.5328), ('city solitary', 0.5167)]\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "def extract_keywords_using_keybert(text):\n",
    "    # Initialize KeyBERT with the desired model\n",
    "    model = KeyBERT('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Extract keywords from the text\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Example usage\n",
    "text = \"In a bustling city, a solitary street performer captivates the crowd with a mesmerizing melody under the glow of neon lights\"\n",
    "keywords = extract_keywords_using_keybert(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ccf6c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neon lights', 'mesmerizing melody', 'bustling city', 'glow', 'crowd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the necessary NLTK data (first-time use only)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def extract_keywords_using_rake(text):\n",
    "    # Initialize RAKE with NLTK's stopwords and set maximum phrase length to 2\n",
    "    custom_stopwords = set(stopwords.words('english'))  # You can add more stopwords if needed\n",
    "    r = Rake(stopwords=custom_stopwords, min_length=1, max_length=2)  # Adjust min_length and max_length here\n",
    "    # Extract keywords from the text\n",
    "    r.extract_keywords_from_text(text)\n",
    "    \n",
    "    # Get the ranked phrases as a list of tuples (phrase, score)\n",
    "    ranked_phrases_with_scores = r.get_ranked_phrases_with_scores()\n",
    "    \n",
    "    # Extract the ranked phrases without scores\n",
    "    ranked_phrases = [phrase for score, phrase in ranked_phrases_with_scores]\n",
    "    \n",
    "    return ranked_phrases\n",
    "\n",
    "# Example usage\n",
    "text = \"In a bustling city, a solitary street performer captivates the crowd with a mesmerizing melody under the glow of neon lights \"\n",
    "keywords = extract_keywords_using_rake(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abc206",
   "metadata": {},
   "source": [
    "## connecting to gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f4568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def get_category(prompt):\n",
    "    API_KEY = \"AIzaSyDX1lheYeca-QP7ZiaGUjvGsHYINcJi7WM\"\n",
    "\n",
    "    genai.configure(api_key=API_KEY)\n",
    "\n",
    "    model_name = \"gemini-1.5-pro-latest\"\n",
    "\n",
    "    # Create a generative model object\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "\n",
    "\n",
    "    # Generate text with some customization options (optional)\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.8,  # Controls randomness (0 = deterministic, 1 = more random)\n",
    "        \"max_output_tokens\": 2048  # Maximum number of tokens to generate\n",
    "    }\n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "\n",
    "    # Print the generated text\n",
    "    print(\"response: \",response.text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a75667",
   "metadata": {},
   "source": [
    "### Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ba7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Artificial Intelligence \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_category(\"Is machine learning a part of Artificial Intelligence, sports, cooking, or something else? If it's something else, what is it? Just wirte the topic only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb14041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Artificial Intelligence \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_category(\"Is machine learning a part of sports, cooking, or something else? If it's something else, what is it? Just wirte the topic only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db035aec",
   "metadata": {},
   "source": [
    "## add mark to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa4f33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    return mysql.connector.connect(user='root', password='Jana2003?',\n",
    "                              host='127.0.0.1', database='grad',\n",
    "                              auth_plugin='mysql_native_password')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a34bb",
   "metadata": {},
   "source": [
    "### get all quizes types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84735fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_quiz_types():\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    quiz_types_query = \"SELECT DISTINCT quiz_type FROM marks\"\n",
    "    \n",
    "    cursor.execute(quiz_types_query)\n",
    "    quiz_types = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return [quiz_type[0] for quiz_type in quiz_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c829e78",
   "metadata": {},
   "source": [
    "### get quiz category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00a0064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_topic(topic):\n",
    "    quiz_types = get_all_quiz_types()\n",
    "    \n",
    "    if not quiz_types:\n",
    "        query = f\"What is the topic of {topic}? Just write the topic only\"\n",
    "    else:\n",
    "        categories_str = \", \".join(quiz_types)\n",
    "        query = f\"Is {topic} a part of {categories_str}, or something else? If it's something else, what is it? Just write the topic only\"\n",
    "    \n",
    "    print(\"category:\", get_category(query))\n",
    "    return get_category(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3a70a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Computer Science \n",
      "\n",
      "category: Computer Science \n",
      "\n",
      "response:  Computer Science \n",
      "\n",
      "The category for 'machine learning' is: Computer Science \n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"machine learning\"\n",
    "category = categorize_topic(topic)\n",
    "print(f\"The category for '{topic}' is: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68c8446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mark(user_id, quiz_type, mark):\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    add_mark_query = (\n",
    "        \"INSERT INTO marks (unique_name, quiz_type, mark) \"\n",
    "        \"VALUES (%s, %s, %s)\"\n",
    "    )\n",
    "    \n",
    "    cursor.execute(add_mark_query, (user_id, categorize_topic(quiz_type), mark))\n",
    "    connection.commit()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c704af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_marks(user_id, quiz_type):\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    avg_marks_query = (\n",
    "        \"SELECT AVG(mark) FROM marks \"\n",
    "        \"WHERE unique_name = %s AND quiz_type = %s\"\n",
    "    )\n",
    "    \n",
    "    cursor.execute(avg_marks_query, (user_id, quiz_type))\n",
    "    avg_mark = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return avg_mark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b7359",
   "metadata": {},
   "source": [
    "## test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1494aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Computer Science \n",
      "\n",
      "category: Computer Science \n",
      "\n",
      "response:  Computer Science \n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_mark('jana', 'machine learning', 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea25f612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Metaphysics \n",
      "\n",
      "category: Metaphysics \n",
      "\n",
      "response:  Philosophy \n",
      "\n",
      "response:  Metaphysics \n",
      "\n",
      "category: Metaphysics \n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\grpc\\_channel.py:1161\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1155\u001b[0m (\n\u001b[0;32m   1156\u001b[0m     state,\n\u001b[0;32m   1157\u001b[0m     call,\n\u001b[0;32m   1158\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1159\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1160\u001b[0m )\n\u001b[1;32m-> 1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\grpc\\_channel.py:1004\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Resource has been exhausted (e.g. check quota).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.217.18.234:443 {created_time:\"2024-06-14T14:01:31.5202343+00:00\", grpc_status:8, grpc_message:\"Resource has been exhausted (e.g. check quota).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m add_mark(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjana\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m85\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43madd_mark\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjana\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m add_mark(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjana\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmachine learning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m88\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Getting average marks for a specific quiz type\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [22], line 10\u001b[0m, in \u001b[0;36madd_mark\u001b[1;34m(user_id, quiz_type, mark)\u001b[0m\n\u001b[0;32m      3\u001b[0m cursor \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m      5\u001b[0m add_mark_query \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO marks (unique_name, quiz_type, mark) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(add_mark_query, (user_id, \u001b[43mcategorize_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquiz_type\u001b[49m\u001b[43m)\u001b[49m, mark))\n\u001b[0;32m     11\u001b[0m connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     13\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn [20], line 11\u001b[0m, in \u001b[0;36mcategorize_topic\u001b[1;34m(topic)\u001b[0m\n\u001b[0;32m      8\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m a part of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategories_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or something else? If it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms something else, what is it? Just write the topic only\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory:\u001b[39m\u001b[38;5;124m\"\u001b[39m, get_category(query))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [12], line 19\u001b[0m, in \u001b[0;36mget_category\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Generate text with some customization options (optional)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.8\u001b[39m,  \u001b[38;5;66;03m# Controls randomness (0 = deterministic, 1 = more random)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_output_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2048\u001b[39m  \u001b[38;5;66;03m# Maximum number of tokens to generate\u001b[39;00m\n\u001b[0;32m     18\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Print the generated text\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse: \u001b[39m\u001b[38;5;124m\"\u001b[39m,response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\generativeai\\generative_models.py:258\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 258\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    259\u001b[0m             request,\n\u001b[0;32m    260\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    261\u001b[0m         )\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:812\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 812\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[0;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    348\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "add_mark('jana', 'machine learning', 88)\n",
    "\n",
    "# Getting average marks for a specific quiz type\n",
    "avg_math_marks = get_avg_marks('jana', 'math')\n",
    "print(f\"Average marks for Jana Doe in Math: {avg_math_marks}\")\n",
    "\n",
    "avg_science_marks = get_avg_marks('jana', 'science')\n",
    "print(f\"Average marks for Jana Doe in Science: {avg_science_marks}\")\n",
    "get_all_quiz_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59082d25",
   "metadata": {},
   "source": [
    "## Retrieve users and their marks avg, who have taken the same tests, received marks higher than 2, and are not followed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "49c3b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_users_with_avg_marks_above(user_name):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        connection = get_db_connection()\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Query to find users who have implemented the same tests as the given user,\n",
    "        # are not followed by the given user, have marks > 2, and return their name + avg marks\n",
    "        #The avg of high marks only, if the user has a mark < 2 it wont be included in the avg\n",
    "        query = \"\"\"\n",
    "            SELECT m.unique_name, AVG(m.mark) AS avg_mark\n",
    "            FROM marks m\n",
    "            WHERE m.quiz_type IN (\n",
    "                SELECT DISTINCT quiz_type\n",
    "                FROM marks\n",
    "                WHERE unique_name = %s\n",
    "            ) AND m.unique_name != %s\n",
    "            AND m.unique_name NOT IN (\n",
    "                SELECT f.following_id\n",
    "                FROM followers f\n",
    "                WHERE f.follower_id = %s\n",
    "            )\n",
    "            AND m.mark > 2\n",
    "            GROUP BY m.unique_name\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query with user_name as parameter\n",
    "        cursor.execute(query, (user_name, user_name, user_name))\n",
    "\n",
    "        # Fetch all the results\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Close cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        return results\n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(f\"Error connecting to MySQL: {error}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ba643f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who have implemented the same tests as jana, are not followed by jana, have marks > 2, and their average marks:\n",
      "aa: 3.5000\n",
      "sara: 4.0000\n"
     ]
    }
   ],
   "source": [
    "user_name = 'jana'  # Replace with the user name you want to query\n",
    "users_with_avg_marks_above = find_users_with_avg_marks_above(user_name)\n",
    "print(f\"Users who have implemented the same tests as {user_name}, are not followed by {user_name}, have marks > 2, and their average marks:\")\n",
    "for user, avg_mark in users_with_avg_marks_above:\n",
    "    print(f\"{user}: {avg_mark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d47682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
