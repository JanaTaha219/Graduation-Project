{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e76502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections.abc import Mapping\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download the pre-trained Word2Vec model\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17eec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5c30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    text = ' '.join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac7d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8483899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vector(text):\n",
    "    word_embeddings = []\n",
    "    for word in text.split():\n",
    "        try:\n",
    "            embedding = w2v_model[word]\n",
    "            word_embeddings.append(embedding)\n",
    "        except KeyError:\n",
    "            # If the word is not found in the vocabulary, skip it\n",
    "            pass\n",
    "    \n",
    "    if len(word_embeddings) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Calculate the average of word embeddings\n",
    "    text_vector = np.mean(word_embeddings, axis=0)\n",
    "    return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_between_texts(text1, text2, limm=True):\n",
    "    # Preprocess the texts\n",
    "    if limm == True:\n",
    "        preprocessed_text1 = apply_lemmatization(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_lemmatization(preprocess_text(text2))\n",
    "    else:\n",
    "        preprocessed_text1 = apply_stemming(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_stemming(preprocess_text(text2))\n",
    "    \n",
    "    # Get text vectors\n",
    "    vector1 = get_text_vector(preprocessed_text1)\n",
    "    vector2 = get_text_vector(preprocessed_text2)\n",
    "    \n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c12c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Text 1 and Text 2 with lemmatization: 0.49738303\n",
      "Cosine Similarity between Text 1 and Text 2 with stemming: 0.46470538\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Tokenization is an important step in natural language processing.\"\n",
    "text2 = \"Sentence tokenization is a technique used to split text into sentences.\"\n",
    "\n",
    "# Calculate cosine similarity between texts\n",
    "similarity = cosine_similarity_between_texts(text1, text2)\n",
    "\n",
    "print(\"Cosine Similarity between Text 1 and Text 2 with lemmatization:\", similarity)\n",
    "similarity = cosine_similarity_between_texts(text1, text2, False)\n",
    "print(\"Cosine Similarity between Text 1 and Text 2 with stemming:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703b4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "db = mysql.connector.connect(user='root', password='Jana2003?',\n",
    "                              host='127.0.0.1', database='grad',\n",
    "                              auth_plugin='mysql_native_password')\n",
    "cursor = db.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5a49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_users_note_except_user_and_followed(username_to_exclude):\n",
    "    # Fetch the list of users that the specified user follows\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT following_id\n",
    "        FROM followers\n",
    "        WHERE follower_id = '{username_to_exclude}'\n",
    "    \"\"\")\n",
    "    followed_users = cursor.fetchall()\n",
    "    \n",
    "    # Extract the list of followed user IDs\n",
    "    followed_user_ids = [user[0] for user in followed_users]\n",
    "    \n",
    "    # Convert the list to a string format suitable for SQL IN clause\n",
    "    followed_user_ids_str = \"', '\".join(followed_user_ids)\n",
    "    \n",
    "    # Include the specified user in the exclusion list\n",
    "    followed_user_ids_str = f\"'{username_to_exclude}', '{followed_user_ids_str}'\"\n",
    "    \n",
    "    # Fetch notes excluding those from the specified user and followed users\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM note\n",
    "        WHERE user_id NOT IN ({followed_user_ids_str})\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    notes = cursor.fetchall()\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2a7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa\n",
      "a\n",
      "aaaaa\n",
      "saraa\n",
      "b\n",
      "sara\n",
      "saraa\n",
      "saraa\n",
      "aaa\n",
      "aaa\n",
      "a\n",
      "a\n",
      "aa\n",
      "aa\n",
      "a\n",
      "jana\n",
      "aa\n",
      "aa\n",
      "jana\n",
      "sara\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "all_users_post_except_specific_user = get_all_users_note_except_user_and_followed(\"rama\")\n",
    "for post in all_users_post_except_specific_user:\n",
    "    print(post[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63d1965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_user_posts(username):\n",
    "    cursor.execute(f\"SELECT text FROM note WHERE user_id = '{username}'\")\n",
    "    posts = cursor.fetchall()\n",
    "    # Convert each tuple to a string\n",
    "    posts_as_strings = [post[0] for post in posts]\n",
    "    return posts_as_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb1b8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_user_posts_using_cosine(user_name, number_of_posts):\n",
    "    user_posts = get_all_user_posts(user_name)\n",
    "\n",
    "    # Get all other users' posts\n",
    "    other_users_posts = get_all_users_note_except_user_and_followed(user_name)\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Initialize a set to store the IDs of processed posts\n",
    "    processed_post_ids = set()\n",
    "\n",
    "    # Loop through each other user's post\n",
    "    for post in other_users_posts:\n",
    "        # Calculate cosine similarity between each user post and the current post\n",
    "        for user_post in user_posts:\n",
    "            similarity = cosine_similarity_between_texts(user_post, post[3])\n",
    "            if similarity and post[0] not in processed_post_ids:  # Check if similarity is not None and post not processed\n",
    "                recommendations.append({\n",
    "                    'id': post[0],              # Get the post ID from the tuple\n",
    "                    'creation_time': post[1],   # Get the creation time from the tuple\n",
    "                    'user_id': post[2],         # Get the user ID from the tuple\n",
    "                    'text': post[3],            # Get the post text from the tuple\n",
    "                    'url': post[4],             # Get the URL from the tuple\n",
    "                    'comment': post[5],         # Get the comment from the tuple\n",
    "                    'similarity': similarity    # Include the calculated similarity\n",
    "                })\n",
    "                # Add the post ID to the set of processed post IDs\n",
    "                processed_post_ids.add(post[0])\n",
    "\n",
    "    # Sort recommendations by similarity (highest first)\n",
    "    recommendations.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Return only the requested number of recommendations\n",
    "    return recommendations[:number_of_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "762dc04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 10,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 22, 79000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Providing timely and constructive feedback is essential for student growth and improvement.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.63822603},\n",
       " {'id': 9,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 20, 91000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Engaging students through interactive activities helps enhance understanding and retention.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.6114806},\n",
       " {'id': 14,\n",
       "  'creation_time': datetime.datetime(2024, 4, 30, 23, 42, 17, 463000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Tailoring instruction to meet diverse student needs ensures that all learners can succeed.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Your%20Own',\n",
       "  'comment': 'bbbb',\n",
       "  'similarity': 0.59020835},\n",
       " {'id': 15,\n",
       "  'creation_time': datetime.datetime(2024, 5, 1, 18, 27, 2, 325000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Using technology in the classroom can enhance learning experiences and access to information.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Google%20Chrome',\n",
       "  'comment': 'bhbhbh',\n",
       "  'similarity': 0.56750226},\n",
       " {'id': 27,\n",
       "  'creation_time': datetime.datetime(2024, 5, 26, 9, 37, 24, 205000),\n",
       "  'user_id': 'sara',\n",
       "  'text': 'Understanding algorithms is crucial for problem-solving and optimizing code performance.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension#:~:text=Extension',\n",
       "  'comment': 'save plzzzz',\n",
       "  'similarity': 0.45019576}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_user_posts_using_cosine(\"aa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ec151e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def euclidean_similarity_between_texts(text1, text2, limm=True):\n",
    "    # Preprocess the texts\n",
    "    if limm == True:\n",
    "        preprocessed_text1 = apply_lemmatization(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_lemmatization(preprocess_text(text2))\n",
    "    else:\n",
    "        preprocessed_text1 = apply_stemming(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_stemming(preprocess_text(text2))\n",
    "    \n",
    "    # Get text vectors\n",
    "    vector1 = get_text_vector(preprocessed_text1)\n",
    "    vector2 = get_text_vector(preprocessed_text2)\n",
    "    \n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate Euclidean distance\n",
    "    distance = euclidean_distances([vector1], [vector2])[0][0]\n",
    "    \n",
    "    # Convert distance to similarity\n",
    "    similarity = 1 / (1 + distance)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "48de089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_user_posts_using_euclidean_distances(user_name, number_of_posts):\n",
    "    \n",
    "    user_posts = get_all_user_posts(user_name)\n",
    "\n",
    "    # Get all other users' posts\n",
    "    other_users_posts = get_all_users_note_except_user_and_followed(user_name)\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Initialize a set to store the IDs of processed posts\n",
    "    processed_post_ids = set()\n",
    "\n",
    "    # Loop through each other user's post\n",
    "    for post in other_users_posts:\n",
    "        # Calculate cosine similarity between each user post and the current post\n",
    "        for user_post in user_posts:\n",
    "            similarity = euclidean_similarity_between_texts(user_post, post[3])\n",
    "            if similarity and post[0] not in processed_post_ids:  # Check if similarity is not None and post not processed\n",
    "                recommendations.append({\n",
    "                    'id': post[0],              # Get the post ID from the tuple\n",
    "                    'creation_time': post[1],   # Get the creation time from the tuple\n",
    "                    'user_id': post[2],         # Get the user ID from the tuple\n",
    "                    'text': post[3],            # Get the post text from the tuple\n",
    "                    'url': post[4],             # Get the URL from the tuple\n",
    "                    'comment': post[5],         # Get the comment from the tuple\n",
    "                    'similarity': similarity    # Include the calculated similarity\n",
    "                })\n",
    "                # Add the post ID to the set of processed post IDs\n",
    "                processed_post_ids.add(post[0])\n",
    "\n",
    "    # Sort recommendations by similarity (highest first)\n",
    "    recommendations.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Return only the requested number of recommendations\n",
    "    return recommendations[:number_of_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0a50e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 9,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 20, 91000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Engaging students through interactive activities helps enhance understanding and retention.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.4728127036489725},\n",
       " {'id': 10,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 22, 79000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Providing timely and constructive feedback is essential for student growth and improvement.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.47229727934145316},\n",
       " {'id': 14,\n",
       "  'creation_time': datetime.datetime(2024, 4, 30, 23, 42, 17, 463000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Tailoring instruction to meet diverse student needs ensures that all learners can succeed.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Your%20Own',\n",
       "  'comment': 'bbbb',\n",
       "  'similarity': 0.46432169471112933},\n",
       " {'id': 15,\n",
       "  'creation_time': datetime.datetime(2024, 5, 1, 18, 27, 2, 325000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Using technology in the classroom can enhance learning experiences and access to information.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Google%20Chrome',\n",
       "  'comment': 'bhbhbh',\n",
       "  'similarity': 0.4528749672501949},\n",
       " {'id': 27,\n",
       "  'creation_time': datetime.datetime(2024, 5, 26, 9, 37, 24, 205000),\n",
       "  'user_id': 'sara',\n",
       "  'text': 'Understanding algorithms is crucial for problem-solving and optimizing code performance.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension#:~:text=Extension',\n",
       "  'comment': 'save plzzzz',\n",
       "  'similarity': 0.4265332665478514}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_user_posts_using_euclidean_distances(\"aa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "892401cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_similarity_between_texts(text1, text2, limm=True):\n",
    "    # Preprocess the texts\n",
    "    if limm == True:\n",
    "        preprocessed_text1 = apply_lemmatization(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_lemmatization(preprocess_text(text2))\n",
    "    else:\n",
    "        preprocessed_text1 = apply_stemming(preprocess_text(text1))\n",
    "        preprocessed_text2 = apply_stemming(preprocess_text(text2))\n",
    "    \n",
    "    # Get text vectors\n",
    "    vector1 = get_text_vector(preprocessed_text1)\n",
    "    vector2 = get_text_vector(preprocessed_text2)\n",
    "    \n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    \n",
    "    # Normalize vectors\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc146366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_user_posts_using_dot_product(user_name, number_of_posts):\n",
    "    \n",
    "    user_posts = get_all_user_posts(user_name)\n",
    "\n",
    "    # Get all other users' posts\n",
    "    other_users_posts = get_all_users_note_except_user_and_followed(user_name)\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Initialize a set to store the IDs of processed posts\n",
    "    processed_post_ids = set()\n",
    "\n",
    "    # Loop through each other user's post\n",
    "    for post in other_users_posts:\n",
    "        # Calculate cosine similarity between each user post and the current post\n",
    "        for user_post in user_posts:\n",
    "            similarity = dot_product_similarity_between_texts(user_post, post[3])\n",
    "            if similarity and post[0] not in processed_post_ids:  # Check if similarity is not None and post not processed\n",
    "                recommendations.append({\n",
    "                    'id': post[0],              # Get the post ID from the tuple\n",
    "                    'creation_time': post[1],   # Get the creation time from the tuple\n",
    "                    'user_id': post[2],         # Get the user ID from the tuple\n",
    "                    'text': post[3],            # Get the post text from the tuple\n",
    "                    'url': post[4],             # Get the URL from the tuple\n",
    "                    'comment': post[5],         # Get the comment from the tuple\n",
    "                    'similarity': similarity    # Include the calculated similarity\n",
    "                })\n",
    "                # Add the post ID to the set of processed post IDs\n",
    "                processed_post_ids.add(post[0])\n",
    "\n",
    "    # Sort recommendations by similarity (highest first)\n",
    "    recommendations.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    # Return only the requested number of recommendations\n",
    "    return recommendations[:number_of_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b76e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 10,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 22, 79000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Providing timely and constructive feedback is essential for student growth and improvement.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.638226},\n",
       " {'id': 9,\n",
       "  'creation_time': datetime.datetime(2024, 4, 16, 21, 2, 20, 91000),\n",
       "  'user_id': 'saraa',\n",
       "  'text': 'Engaging students through interactive activities helps enhance understanding and retention.',\n",
       "  'url': 'www.hello.com',\n",
       "  'comment': \"this is a's comment\",\n",
       "  'similarity': 0.61148053},\n",
       " {'id': 14,\n",
       "  'creation_time': datetime.datetime(2024, 4, 30, 23, 42, 17, 463000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Tailoring instruction to meet diverse student needs ensures that all learners can succeed.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Your%20Own',\n",
       "  'comment': 'bbbb',\n",
       "  'similarity': 0.59020835},\n",
       " {'id': 15,\n",
       "  'creation_time': datetime.datetime(2024, 5, 1, 18, 27, 2, 325000),\n",
       "  'user_id': 'a',\n",
       "  'text': 'Using technology in the classroom can enhance learning experiences and access to information.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension/#how-to-create-a-chrome-extension##:~:text=Google%20Chrome',\n",
       "  'comment': 'bhbhbh',\n",
       "  'similarity': 0.5675022},\n",
       " {'id': 27,\n",
       "  'creation_time': datetime.datetime(2024, 5, 26, 9, 37, 24, 205000),\n",
       "  'user_id': 'sara',\n",
       "  'text': 'Understanding algorithms is crucial for problem-solving and optimizing code performance.',\n",
       "  'url': 'https://www.freecodecamp.org/news/building-chrome-extension#:~:text=Extension',\n",
       "  'comment': 'save plzzzz',\n",
       "  'similarity': 0.4501958}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_user_posts_using_dot_product(\"aa\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d82a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('street performer', 0.6253), ('melody glow', 0.5632), ('mesmerizing melody', 0.5517), ('solitary street', 0.5328), ('city solitary', 0.5167)]\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "def extract_keywords_using_keybert(text):\n",
    "    # Initialize KeyBERT with the desired model\n",
    "    model = KeyBERT('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Extract keywords from the text\n",
    "    keywords = model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Example usage\n",
    "text = \"In a bustling city, a solitary street performer captivates the crowd with a mesmerizing melody under the glow of neon lights\"\n",
    "keywords = extract_keywords_using_keybert(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ccf6c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neon lights', 'mesmerizing melody', 'bustling city', 'glow', 'crowd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\HP\n",
      "[nltk_data]     User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the necessary NLTK data (first-time use only)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def extract_keywords_using_rake(text):\n",
    "    # Initialize RAKE with NLTK's stopwords and set maximum phrase length to 2\n",
    "    custom_stopwords = set(stopwords.words('english'))  # You can add more stopwords if needed\n",
    "    r = Rake(stopwords=custom_stopwords, min_length=1, max_length=2)  # Adjust min_length and max_length here\n",
    "    # Extract keywords from the text\n",
    "    r.extract_keywords_from_text(text)\n",
    "    \n",
    "    # Get the ranked phrases as a list of tuples (phrase, score)\n",
    "    ranked_phrases_with_scores = r.get_ranked_phrases_with_scores()\n",
    "    \n",
    "    # Extract the ranked phrases without scores\n",
    "    ranked_phrases = [phrase for score, phrase in ranked_phrases_with_scores]\n",
    "    \n",
    "    return ranked_phrases\n",
    "\n",
    "# Example usage\n",
    "text = \"In a bustling city, a solitary street performer captivates the crowd with a mesmerizing melody under the glow of neon lights \"\n",
    "keywords = extract_keywords_using_rake(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abc206",
   "metadata": {},
   "source": [
    "## connecting to gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f4568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def get_category(prompt):\n",
    "    API_KEY = \"AIzaSyDX1lheYeca-QP7ZiaGUjvGsHYINcJi7WM\"\n",
    "\n",
    "    genai.configure(api_key=API_KEY)\n",
    "\n",
    "    model_name = \"gemini-1.5-pro-latest\"\n",
    "\n",
    "    # Create a generative model object\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "\n",
    "\n",
    "    # Generate text with some customization options (optional)\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.8,  # Controls randomness (0 = deterministic, 1 = more random)\n",
    "        \"max_output_tokens\": 2048  # Maximum number of tokens to generate\n",
    "    }\n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "\n",
    "    # Print the generated text\n",
    "    print(\"response: \",response.text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a75667",
   "metadata": {},
   "source": [
    "### Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ba7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Artificial Intelligence \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_category(\"Is machine learning a part of Artificial Intelligence, sports, cooking, or something else? If it's something else, what is it? Just wirte the topic only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb14041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Artificial Intelligence \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_category(\"Is machine learning a part of sports, cooking, or something else? If it's something else, what is it? Just wirte the topic only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db035aec",
   "metadata": {},
   "source": [
    "## add mark to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4f33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    return mysql.connector.connect(user='root', password='Jana2003?',\n",
    "                              host='127.0.0.1', database='grad',\n",
    "                              auth_plugin='mysql_native_password')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a34bb",
   "metadata": {},
   "source": [
    "### get all quizes types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84735fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_quiz_types():\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    quiz_types_query = \"SELECT DISTINCT quiz_type FROM marks\"\n",
    "    \n",
    "    cursor.execute(quiz_types_query)\n",
    "    quiz_types = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return [quiz_type[0] for quiz_type in quiz_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c829e78",
   "metadata": {},
   "source": [
    "### get quiz category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a0064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_topic(topic):\n",
    "    quiz_types = get_all_quiz_types()\n",
    "    \n",
    "    if not quiz_types:\n",
    "        query = f\"What is the topic of {topic}? Just write the topic only\"\n",
    "    else:\n",
    "        categories_str = \", \".join(quiz_types)\n",
    "        query = f\"Is {topic} a part of {categories_str}, or something else? If it's something else, what is it? Just write the topic only\"\n",
    "    \n",
    "    print(\"category:\", get_category(query))\n",
    "    return get_category(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a70a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Computer Science \n",
      "\n",
      "category: Computer Science \n",
      "\n",
      "response:  Computer Science \n",
      "\n",
      "The category for 'machine learning' is: Computer Science \n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"machine learning\"\n",
    "category = categorize_topic(topic)\n",
    "print(f\"The category for '{topic}' is: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c8446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mark(user_id, quiz_type, mark):\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    add_mark_query = (\n",
    "        \"INSERT INTO marks (unique_name, quiz_type, mark) \"\n",
    "        \"VALUES (%s, %s, %s)\"\n",
    "    )\n",
    "    \n",
    "    cursor.execute(add_mark_query, (user_id, categorize_topic(quiz_type), mark))\n",
    "    connection.commit()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c704af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_marks(user_id, quiz_type):\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    avg_marks_query = (\n",
    "        \"SELECT AVG(mark) FROM marks \"\n",
    "        \"WHERE unique_name = %s AND quiz_type = %s\"\n",
    "    )\n",
    "    \n",
    "    cursor.execute(avg_marks_query, (user_id, quiz_type))\n",
    "    avg_mark = cursor.fetchone()[0]\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return avg_mark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b7359",
   "metadata": {},
   "source": [
    "## test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea25f612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  Computer Science \n",
      "\n",
      "category: Computer Science \n",
      "\n",
      "response:  Computer Science \n",
      "\n",
      "Average marks for Jana in Math: 1.8333\n",
      "Average marks for Jana in Science: 4.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['math', 'science', 'Computer Science', 'Computer Science \\n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_mark('jana', 'machine learning', 88)\n",
    "\n",
    "# Getting average marks for a specific quiz type\n",
    "avg_math_marks = get_avg_marks('jana', 'math')\n",
    "print(f\"Average marks for Jana in Math: {avg_math_marks}\")\n",
    "\n",
    "avg_science_marks = get_avg_marks('jana', 'science')\n",
    "print(f\"Average marks for Jana in Science: {avg_science_marks}\")\n",
    "get_all_quiz_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59082d25",
   "metadata": {},
   "source": [
    "## Retrieve users and their marks avg, who have taken the same tests, received marks higher than 2, and are not followed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49c3b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unfollowed_users_with_avg_above_2(user_name):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        connection = get_db_connection()\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Query to find users who have implemented the same tests as the given user,\n",
    "        # are not followed by the given user, and their average mark is > 2\n",
    "        query = \"\"\"\n",
    "            SELECT m.unique_name, AVG(m.mark) AS avg_mark\n",
    "            FROM marks m\n",
    "            WHERE m.quiz_type IN (\n",
    "                SELECT DISTINCT quiz_type\n",
    "                FROM marks\n",
    "                WHERE unique_name = %s\n",
    "            ) AND m.unique_name != %s\n",
    "            AND m.unique_name NOT IN (\n",
    "                SELECT f.following_id\n",
    "                FROM followers f\n",
    "                WHERE f.follower_id = %s\n",
    "            )\n",
    "            GROUP BY m.unique_name\n",
    "            HAVING avg_mark > 2\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query with user_name as parameter\n",
    "        cursor.execute(query, (user_name, user_name, user_name))\n",
    "\n",
    "        # Fetch all the results\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Close cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        return results\n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(f\"Error connecting to MySQL: {error}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba643f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who have implemented the same tests as jana, are not followed by jana, and have an average mark > 2:\n",
      "aa: 3.5000\n",
      "sara: 4.0000\n"
     ]
    }
   ],
   "source": [
    "user_name = 'jana'  # Replace with the user name you want to query\n",
    "users_with_avg_marks_above = find_users_with_avg_marks_above(user_name)\n",
    "print(f\"Users who have implemented the same tests as {user_name}, are not followed by {user_name}, and have an average mark > 2:\")\n",
    "for user, avg_mark in users_with_avg_marks_above:\n",
    "    print(f\"{user}: {avg_mark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "284cd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unfollowed_users_with_avg_above_2(quiz_type, user_unique_name):\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor(dictionary=True)\n",
    "    \n",
    "    # Fetch the users who had a test on the given subject and their average mark is > 2\n",
    "    query = \"\"\"\n",
    "    SELECT m.unique_name, AVG(m.mark) as average_mark\n",
    "    FROM marks m\n",
    "    WHERE m.quiz_type = %s\n",
    "    GROUP BY m.unique_name\n",
    "    HAVING AVG(m.mark) > 2\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query, (quiz_type,))\n",
    "    users_above_2 = cursor.fetchall()\n",
    "    \n",
    "    users_above_2 = {user['unique_name']: user['average_mark'] for user in users_above_2}\n",
    "    \n",
    "    # Fetch the users followed by the given user\n",
    "    query = \"\"\"\n",
    "    SELECT f.following_id\n",
    "    FROM followers f\n",
    "    WHERE f.follower_id = %s\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query, (user_unique_name,))\n",
    "    followed_users = cursor.fetchall()\n",
    "    \n",
    "    followed_users = {user['following_id'] for user in followed_users}\n",
    "    \n",
    "    # Get the users who are not followed by the given user\n",
    "    unfollowed_users_with_avg = {user: avg for user, avg in users_above_2.items() if user not in followed_users}\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    # Sort the result by average mark in descending order\n",
    "    sorted_unfollowed_users_with_avg = dict(sorted(unfollowed_users_with_avg.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return sorted_unfollowed_users_with_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654d9592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user who has a test on subject + got high mark + not followed by user:\n",
      "User: sara, Average Mark: 5.0000\n",
      "User: aa, Average Mark: 3.0000\n"
     ]
    }
   ],
   "source": [
    "quiz_type = \"math\"\n",
    "user_unique_name = \"jana\"\n",
    "result = get_unfollowed_users_with_avg_above_2(quiz_type, user_unique_name)\n",
    "print(\"user who has a test on subject + got high mark + not followed by user:\")\n",
    "for user, avg in result.items():\n",
    "    print(f\"User: {user}, Average Mark: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471c27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
